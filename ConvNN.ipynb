{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Simple Deep Convolutional Neural Network for sklearn-MNIST\n",
    "Input: 8x8 greyscale images\n",
    "Layer 1: Conv 3x3 x16 - Leaky ReLU\n",
    "Layer 2: FC 128 - Leaky ReLU\n",
    "Layer 3: FC 128 - Leaky ReLU\n",
    "Layer 4: FC 10 - Softmax\n",
    "\n",
    "@author: TÃ¢m Le Minh\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "class ConvNN:\n",
    "    \n",
    "    mini_batch = 32\n",
    "    nb_epoch = 1\n",
    "    W = []\n",
    "    b = []\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def load_data(self):\n",
    "        digits = load_digits()\n",
    "        \n",
    "        X = digits.images\n",
    "        X_norm, self.mu_X, self.sigma_X = normalize_data(X)\n",
    "        \n",
    "        labels = digits.target\n",
    "        Y = np.zeros((X.shape[0], 10))\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            Y[i][label] = 1\n",
    "        \n",
    "        self.X_train, self.X_test, self.Y_train, self.Y_test = train_test_split(X_norm, Y, test_size=0.2, shuffle=False)\n",
    "        self.n_sample_train = self.X_train.shape[0]\n",
    "        \n",
    "    def initialize_weights(self):\n",
    "        self.W = []\n",
    "        self.b = []\n",
    "        \n",
    "        W_1 = np.sqrt(2./9)*(np.random.sample((16,3,3)))\n",
    "        \n",
    "        W_2 = np.sqrt(2./1024)*(np.random.sample((128,1024)))\n",
    "        b_2 = np.zeros((1,128))\n",
    "        W_3 = np.sqrt(2./128)*(np.random.sample((128,128)))\n",
    "        b_3 = np.zeros((1,128))\n",
    "        W_4 = np.sqrt(2./128)*(np.random.sample((10,128)))\n",
    "        b_4 = np.zeros((1,10))\n",
    "        \n",
    "        self.W.append(0)\n",
    "        self.W.append(W_1)\n",
    "        self.W.append(W_2)\n",
    "        self.W.append(W_3)\n",
    "        self.W.append(W_4)\n",
    "        self.b.append(0)\n",
    "        self.b.append(0)\n",
    "        self.b.append(b_2)\n",
    "        self.b.append(b_3)\n",
    "        self.b.append(b_4)\n",
    "        \n",
    "    def load_weights(self, path, epoch):\n",
    "        self.W = []\n",
    "        self.b = []\n",
    "        W_1 = np.load(path + 'e' + epoch + '_w1.npz')['arr_0']\n",
    "        W_2 = np.load(path + 'e' + epoch + '_w2.npz')['arr_0']\n",
    "        W_3 = np.load(path + 'e' + epoch + '_w3.npz')['arr_0']\n",
    "        W_4 = np.load(path + 'e' + epoch + '_w4.npz')['arr_0']\n",
    "        b_2 = np.load(path + 'e' + epoch + '_b2.npz')['arr_0']\n",
    "        b_3 = np.load(path + 'e' + epoch + '_b3.npz')['arr_0']\n",
    "        b_4 = np.load(path + 'e' + epoch + '_b4.npz')['arr_0']  \n",
    "        \n",
    "        self.W.append(0)\n",
    "        self.W.append(W_1)\n",
    "        self.W.append(W_2)\n",
    "        self.W.append(W_3)\n",
    "        self.W.append(W_4)\n",
    "        self.b.append(0)\n",
    "        self.b.append(0)\n",
    "        self.b.append(b_2)\n",
    "        self.b.append(b_3)\n",
    "        self.b.append(b_4)\n",
    "        \n",
    "    def train(self, l_rate=0.01, l_decay=0, mini_batch=64, nb_epoch=100, verbose=True, plot=False):\n",
    "        self.mini_batch = mini_batch\n",
    "        self.nb_epoch = nb_epoch\n",
    "        number_mini_batch = self.n_sample_train/self.mini_batch + 1\n",
    "        self.alpha = l_rate\n",
    "        for e in range(0, nb_epoch):\n",
    "            for i in range(0, number_mini_batch):\n",
    "                if i!=number_mini_batch-1:\n",
    "                    self.W, self.b, J = fw_bk_prop(self.X_train[mini_batch*i:mini_batch*(i+1),:,:], \n",
    "                                                   self.Y_train[mini_batch*i:mini_batch*(i+1)], \n",
    "                                                   self.W, \n",
    "                                                   self.b, \n",
    "                                                   self.alpha/(l_decay*e+1))\n",
    "                else:\n",
    "                    self.W, self.b, J = fw_bk_prop(self.X_train[mini_batch*i:,:,:], \n",
    "                                                   self.Y_train[mini_batch*i:], \n",
    "                                                   self.W, \n",
    "                                                   self.b, \n",
    "                                                   self.alpha/(l_decay*e+1))\n",
    "\n",
    "            self.train_losses.append(J)\n",
    "            pred, test_score = fw_prop(self.X_test, self.Y_test, self.W, self.b)\n",
    "            self.test_losses.append(test_score)\n",
    "\n",
    "            if verbose and e%10 == 0:\n",
    "                print(\"J: \" + str(J))\n",
    "                \n",
    "        if plot:\n",
    "            self.plot_losses()\n",
    "                \n",
    "    def simple_prediction(self, idx_in_test_set, plot=True):\n",
    "        data = self.X_test[idx_in_test_set,:,:].reshape((1,8,8))\n",
    "        image = unnormalize_data(data, self.mu_X, self.sigma_X)\n",
    "        label = self.Y_test[idx_in_test_set,:].reshape((1,10))\n",
    "        \n",
    "        pred, score = fw_prop(data, label, self.W, self.b)\n",
    "        print(\"Truth: \" + str(np.argmax(label)))\n",
    "        print(\"Predicted: \" + str(np.argmax(pred)))\n",
    "        \n",
    "        if plot:\n",
    "            plt.imshow(image[0])\n",
    "        \n",
    "    def plot_losses(self):\n",
    "        plt.plot(np.arange(self.nb_epoch), self.train_losses, np.arange(self.nb_epoch), self.test_losses)\n",
    "        \n",
    "    def save_weights(self, path):\n",
    "        np.savez_compressed('e' + str(self.nb_epoch) + '_w1.npz', self.W[1])\n",
    "        np.savez_compressed('e' + str(self.nb_epoch) + '_w2.npz', self.W[2])\n",
    "        np.savez_compressed('e' + str(self.nb_epoch) + '_w3.npz', self.W[3])\n",
    "        np.savez_compressed('e' + str(self.nb_epoch) + '_w4.npz', self.W[4])\n",
    "        np.savez_compressed('e' + str(self.nb_epoch) + '_b2.npz', self.b[2])\n",
    "        np.savez_compressed('e' + str(self.nb_epoch) + '_b3.npz', self.b[3])\n",
    "        np.savez_compressed('e' + str(self.nb_epoch) + '_b4.npz', self.b[4])\n",
    "        \n",
    "        \n",
    "def conv_output(x, filters, mode='valid'):\n",
    "    if mode=='valid':\n",
    "        z = np.zeros((x.shape[0], filters.shape[0], x.shape[1]-filters.shape[1]+1, x.shape[2]-filters.shape[2]+1))\n",
    "    elif mode=='same':\n",
    "        z = np.zeros((x.shape[0], filters.shape[0], x.shape[1], x.shape[2]))\n",
    "    else:\n",
    "        raise ValueError(\"Convolution mode must be 'valid' or 'same'\")\n",
    "        \n",
    "    for sample in range(x.shape[0]):    \n",
    "        for i, f in enumerate(filters):\n",
    "            z[sample][i] = convolve2d(x[sample], f, mode=mode)\n",
    "        \n",
    "    return z\n",
    "\n",
    "def dW_conv(dZ_conv, x, filt_shape):\n",
    "    dW = np.zeros(filt_shape)\n",
    "    for c in range(filt_shape[0]):\n",
    "        for a in range(filt_shape[1]):\n",
    "            for b in range(filt_shape[2]):\n",
    "                for k in range(x.shape[0]):\n",
    "                    for i in range(x.shape[1]-filt_shape[1]):\n",
    "                        for j in range(x.shape[2]-filt_shape[2]):\n",
    "                            dW[c,a,b] +=dZ_conv[k,c,i,j] *x[k,i+a,j+b]\n",
    "    return dW\n",
    "\n",
    "def inv_filter(filt):\n",
    "    return np.flip(np.flip(filt, axis=0), axis=1)\n",
    "    \n",
    "def leaky_relu(x):\n",
    "    if x >=0:\n",
    "        return x\n",
    "    else:\n",
    "        return -0.01*x\n",
    "    \n",
    "def d_leaky_relu(x):\n",
    "    if x >=0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return -0.01\n",
    "    \n",
    "def softmax(x):\n",
    "    x -= np.max(x, axis=1).reshape((x.shape[0],1))\n",
    "    result = (np.exp(x))/(np.sum(np.exp(x), axis=1, keepdims=True))\n",
    "    return result\n",
    "    \n",
    "def loss(pred, y):\n",
    "    loss = -1.*np.sum(y*np.log(pred+0.001)/y.shape[0])\n",
    "    return loss\n",
    "\n",
    "def fw_prop(X, Y, W, b):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    nh_0 = X.shape[1]\n",
    "    nw_0 = X.shape[2]\n",
    "    nc_1 = W[1].shape[0]\n",
    "    n_1 = nc_1*nh_0*nw_0\n",
    "    \n",
    "    n_2 = W[2].shape[0]\n",
    "    n_3 = W[3].shape[0]\n",
    "    n_4 = W[4].shape[0]\n",
    "    A_0 = X.reshape((m, nh_0, nw_0))\n",
    "    \n",
    "    Z_1 = conv_output(X, W[1], mode='same')\n",
    "    A_1 = np.vectorize(leaky_relu)(Z_1)\n",
    "\n",
    "    Z_2 = np.dot(A_1.reshape((m,n_1)), W[2].T) + b[2]\n",
    "    A_2 = np.vectorize(leaky_relu)(Z_2)\n",
    "    \n",
    "    Z_3 = np.dot(A_2.reshape((m,n_2)), W[3].T) + b[3]\n",
    "    A_3 = np.vectorize(leaky_relu)(Z_3)\n",
    "    \n",
    "    Z_4 = np.dot(A_3.reshape((m,n_3)), W[4].T) + b[4]\n",
    "    A_4 = softmax(Z_4)\n",
    "    \n",
    "    score = loss(A_4, Y)\n",
    "    return A_4, score\n",
    "\n",
    "def fw_bk_prop(X, Y, W, b, alpha):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    nh_0 = X.shape[1]\n",
    "    nw_0 = X.shape[2]\n",
    "    nc_1 = W[1].shape[0]\n",
    "    n_1 = nc_1*nh_0*nw_0\n",
    "    \n",
    "    n_2 = W[2].shape[0]\n",
    "    n_3 = W[3].shape[0]\n",
    "    n_4 = W[4].shape[0]\n",
    "    A_0 = X.reshape((m, nh_0, nw_0))\n",
    "\n",
    "    Z_1 = conv_output(X, W[1], mode='same')\n",
    "    A_1 = np.vectorize(leaky_relu)(Z_1)\n",
    "    dA_1 = np.vectorize(d_leaky_relu)(Z_1)\n",
    "\n",
    "    Z_2 = np.dot(A_1.reshape((m,n_1)), W[2].T) + b[2]\n",
    "    A_2 = np.vectorize(leaky_relu)(Z_2)\n",
    "    dA_2 = np.vectorize(d_leaky_relu)(Z_2)\n",
    "    \n",
    "    Z_3 = np.dot(A_2.reshape((m,n_2)), W[3].T) + b[3]\n",
    "    A_3 = np.vectorize(leaky_relu)(Z_3)\n",
    "    dA_3 = np.vectorize(d_leaky_relu)(Z_3)\n",
    "    \n",
    "    Z_4 = np.dot(A_3.reshape((m,n_3)), W[4].T) + b[4]\n",
    "    A_4 = softmax(Z_4)\n",
    "    \n",
    "    score = loss(A_4, Y)\n",
    "    \n",
    "    dZ_4 = A_4 - Y\n",
    "    dW_4 = (1./m)*np.dot(dZ_4.T, A_3)\n",
    "    db_4 = (1./m)*np.sum(dZ_4, axis=0, keepdims=True)\n",
    "    \n",
    "    dZ_3 = np.dot(dZ_4, W[4])*dA_3\n",
    "    dW_3 = (1./m)*np.dot(dZ_3.T, A_2)\n",
    "    db_3 = (1./m)*np.sum(dZ_3, axis=0, keepdims=True)\n",
    "    \n",
    "    dZ_2 = np.dot(dZ_3, W[3])*dA_2\n",
    "    dW_2 = (1./m)*np.dot(dZ_2.T, A_1.reshape((m,n_1)))\n",
    "    db_2 = (1./m)*np.sum(dZ_2, axis=0, keepdims=True)\n",
    "    \n",
    "    dZ_1_flat = np.dot(dZ_2, W[2])*dA_1.reshape((m,n_1))\n",
    "    dZ_1 = dZ_1_flat.reshape(Z_1.shape)\n",
    "    dW_1 = (1./m)*dW_conv(dZ_1, X, W[1].shape)\n",
    "    \n",
    "    W[1]-=alpha*dW_1\n",
    "    W[2]-=alpha*dW_2\n",
    "    W[3]-=alpha*dW_3\n",
    "    W[4]-=alpha*dW_4\n",
    "    b[2]-=alpha*db_2\n",
    "    b[3]-=alpha*db_3\n",
    "    b[4]-=alpha*db_4\n",
    "    \n",
    "    return W, b, score\n",
    "    \n",
    "def normalize_data(data, epsilon=10e-8):\n",
    "    epsilon = 10e-8\n",
    "    mu = np.mean(data, axis=0)\n",
    "    sigma = np.var(data, axis=0)\n",
    "    norm_data = (data-mu)/(sigma+epsilon)\n",
    "    return norm_data, mu, sigma\n",
    "\n",
    "def unnormalize_data(norm_data, mu, sigma, epsilon=10e-8):\n",
    "    data = norm_data*(sigma+epsilon) + mu\n",
    "    return data\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = ConvNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.load_data()\n",
    "nn.initialize_weights()\n",
    "#nn.load_weights(\"save/ConvNN/\", \"100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.train(l_rate=0.01, l_decay=0, mini_batch=64, nb_epoch=100, verbose=True, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.simple_prediction(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.save_weights('.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
