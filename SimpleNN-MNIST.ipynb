{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Simple Deep Neural Network for sklearn-MNIST\n",
    "Input: 8x8 greyscale images\n",
    "Layer 1: FC 128 - Leaky ReLU\n",
    "Layer 2: FC 128 - Leaky ReLU\n",
    "Layer 3: FC 10 - Softmax\n",
    "\n",
    "@author: TÃ¢m Le Minh\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class SimpleNN:\n",
    "    \n",
    "    mini_batch = 32\n",
    "    nb_epoch = 1\n",
    "    W = []\n",
    "    b = []\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def load_data(self):\n",
    "        digits = load_digits()\n",
    "        \n",
    "        X = digits.images\n",
    "        X_norm, self.mu_X, self.sigma_X = normalize_data(X)\n",
    "        \n",
    "        labels = digits.target\n",
    "        Y = np.zeros((X.shape[0], 10))\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            Y[i][label] = 1\n",
    "        \n",
    "        self.X_train, self.X_test, self.Y_train, self.Y_test = train_test_split(X_norm, Y, test_size=0.2, shuffle=False)\n",
    "        self.n_sample_train = self.X_train.shape[0]\n",
    "        \n",
    "    def initialize_weights(self):\n",
    "        self.W = []\n",
    "        self.b = []\n",
    "        W_1 = np.sqrt(2./64)*(np.random.sample((128,64)))\n",
    "        b_1 = np.zeros((1,128))\n",
    "        W_2 = np.sqrt(2./128)*(np.random.sample((128,128)))\n",
    "        b_2 = np.zeros((1,128))\n",
    "        W_3 = np.sqrt(2./128)*(np.random.sample((10,128)))\n",
    "        b_3 = np.zeros((1,10))\n",
    "        \n",
    "        self.W.append(0)\n",
    "        self.W.append(W_1)\n",
    "        self.W.append(W_2)\n",
    "        self.W.append(W_3)\n",
    "        self.b.append(0)\n",
    "        self.b.append(b_1)\n",
    "        self.b.append(b_2)\n",
    "        self.b.append(b_3)\n",
    "        \n",
    "    def load_weights(self, path, epoch):\n",
    "        self.W = []\n",
    "        self.b = []\n",
    "        W_1 = np.load(path + 'e' + epoch + '_w1.npz')['arr_0']\n",
    "        W_2 = np.load(path + 'e' + epoch + '_w2.npz')['arr_0']\n",
    "        W_3 = np.load(path + 'e' + epoch + '_w3.npz')['arr_0']\n",
    "        b_1 = np.load(path + 'e' + epoch + '_b1.npz')['arr_0']\n",
    "        b_2 = np.load(path + 'e' + epoch + '_b2.npz')['arr_0']\n",
    "        b_3 = np.load(path + 'e' + epoch + '_b3.npz')['arr_0']  \n",
    "        \n",
    "        self.W.append(0)\n",
    "        self.W.append(W_1)\n",
    "        self.W.append(W_2)\n",
    "        self.W.append(W_3)\n",
    "        self.b.append(0)\n",
    "        self.b.append(b_1)\n",
    "        self.b.append(b_2)\n",
    "        self.b.append(b_3)\n",
    "        \n",
    "    def train(self, l_rate=0.01, l_decay=0, mini_batch=64, nb_epoch=100, verbose=True, plot=False):\n",
    "        self.mini_batch = mini_batch\n",
    "        self.nb_epoch = nb_epoch\n",
    "        number_mini_batch = int(self.n_sample_train/self.mini_batch + 1)\n",
    "        self.alpha = l_rate\n",
    "        for e in range(0, nb_epoch):\n",
    "            for i in range(0, number_mini_batch):\n",
    "                if i!=number_mini_batch-1:\n",
    "                    self.W, self.b, J = fw_bk_prop(self.X_train[mini_batch*i:mini_batch*(i+1),:,:], \n",
    "                                                   self.Y_train[mini_batch*i:mini_batch*(i+1)], \n",
    "                                                   self.W, \n",
    "                                                   self.b, \n",
    "                                                   self.alpha/(l_decay*e+1))\n",
    "                else:\n",
    "                    self.W, self.b, J = fw_bk_prop(self.X_train[mini_batch*i:,:,:], \n",
    "                                                   self.Y_train[mini_batch*i:], \n",
    "                                                   self.W, \n",
    "                                                   self.b, \n",
    "                                                   self.alpha/(l_decay*e+1))\n",
    "\n",
    "            self.train_losses.append(J)\n",
    "            pred, test_score = fw_prop(self.X_test, self.Y_test, self.W, self.b)\n",
    "            self.test_losses.append(test_score)\n",
    "\n",
    "            if verbose and e%10 == 0:\n",
    "                print(\"J: \" + str(J))\n",
    "                \n",
    "        if plot:\n",
    "            self.plot_losses()\n",
    "                \n",
    "    def simple_prediction(self, idx_in_test_set, verbose=True, plot=True):\n",
    "        data = self.X_test[idx_in_test_set,:,:].reshape((1,8,8))\n",
    "        image = unnormalize_data(data, self.mu_X, self.sigma_X)\n",
    "        label = self.Y_test[idx_in_test_set,:].reshape((1,10))\n",
    "        \n",
    "        pred, score = fw_prop(data, label, self.W, self.b)\n",
    "        label_true = np.argmax(label)\n",
    "        label_pred = np.argmax(pred)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Truth: \" + str(label_true))\n",
    "            print(\"Predicted: \" + str(label_pred))\n",
    "        if plot:\n",
    "            plt.figure(figsize=(6,3))\n",
    "            plt.subplot(1,2,1)\n",
    "            plot_image(pred.reshape((10,)), label_true, image[0])\n",
    "            plt.subplot(1,2,2)\n",
    "            plot_value_array(pred.reshape((10,)), label_true)\n",
    "            \n",
    "        if label_true == label_pred:\n",
    "            success = 1.\n",
    "        else:\n",
    "            success = 0.\n",
    "            \n",
    "        return success\n",
    "            \n",
    "    def test_accuracy(self):\n",
    "        counter = 0\n",
    "        for i in range(0, self.X_test.shape[0]):\n",
    "            counter += self.simple_prediction(i, verbose=False, plot=False)\n",
    "        return counter/self.X_test.shape[0]\n",
    "        \n",
    "    def plot_losses(self):\n",
    "        plt.plot(np.arange(self.nb_epoch), self.train_losses, np.arange(self.nb_epoch), self.test_losses)\n",
    "        \n",
    "    def save_weights(self, path):\n",
    "        np.savez_compressed('e' + str(self.nb_epoch) + '_w1.npz', self.W[1])\n",
    "        np.savez_compressed('e' + str(self.nb_epoch) + '_w2.npz', self.W[2])\n",
    "        np.savez_compressed('e' + str(self.nb_epoch) + '_w3.npz', self.W[3])\n",
    "        np.savez_compressed('e' + str(self.nb_epoch) + '_b1.npz', self.b[1])\n",
    "        np.savez_compressed('e' + str(self.nb_epoch) + '_b2.npz', self.b[2])\n",
    "        np.savez_compressed('e' + str(self.nb_epoch) + '_b3.npz', self.b[3])\n",
    "        \n",
    "\n",
    "\n",
    "def leaky_relu(x):\n",
    "    if x >=0:\n",
    "        return x\n",
    "    else:\n",
    "        return -0.01*x\n",
    "    \n",
    "def d_leaky_relu(x):\n",
    "    if x >=0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return -0.01\n",
    "    \n",
    "def softmax(x):\n",
    "    x -= np.max(x, axis=1).reshape((x.shape[0],1))\n",
    "    result = (np.exp(x))/(np.sum(np.exp(x), axis=1, keepdims=True))\n",
    "    return result\n",
    "    \n",
    "def loss(pred, y):\n",
    "    loss = -1.*np.sum(y*np.log(pred+0.001)/y.shape[0])\n",
    "    return loss\n",
    "\n",
    "def fw_prop(X, Y, W, b):\n",
    "    m = X.shape[0]\n",
    "    n_0 = X.shape[1]*X.shape[2]\n",
    "    n_1 = W[1].shape[0]\n",
    "    n_2 = W[2].shape[0]\n",
    "    n_3 = W[3].shape[0]\n",
    "    A_0 = X.reshape((m,n_0))\n",
    "    \n",
    "    Z_1 = np.dot(A_0.reshape((m,n_0)), W[1].T) + b[1]\n",
    "    A_1 = np.vectorize(leaky_relu)(Z_1)\n",
    "    \n",
    "    Z_2 = np.dot(A_1.reshape((m,n_1)), W[2].T) + b[2]\n",
    "    A_2 = np.vectorize(leaky_relu)(Z_2)\n",
    "    \n",
    "    Z_3 = np.dot(A_2.reshape((m,n_2)), W[3].T) + b[3]\n",
    "    A_3 = softmax(Z_3)\n",
    "    \n",
    "    score = loss(A_3, Y)\n",
    "    return A_3, score\n",
    "\n",
    "def fw_bk_prop(X, Y, W, b, alpha):\n",
    "    m = X.shape[0]\n",
    "    n_0 = X.shape[1]*X.shape[2]\n",
    "    n_1 = W[1].shape[0]\n",
    "    n_2 = W[2].shape[0]\n",
    "    n_3 = W[3].shape[0]\n",
    "    A_0 = X.reshape((m,n_0))\n",
    "    \n",
    "    Z_1 = np.dot(A_0.reshape((m,n_0)), W[1].T) + b[1]\n",
    "    A_1 = np.vectorize(leaky_relu)(Z_1)\n",
    "    dA_1 = np.vectorize(d_leaky_relu)(Z_1)\n",
    "    \n",
    "    Z_2 = np.dot(A_1.reshape((m,n_1)), W[2].T) + b[2]\n",
    "    A_2 = np.vectorize(leaky_relu)(Z_2)\n",
    "    dA_2 = np.vectorize(d_leaky_relu)(Z_2)\n",
    "    \n",
    "    Z_3 = np.dot(A_2.reshape((m,n_2)), W[3].T) + b[3]\n",
    "    A_3 = softmax(Z_3)\n",
    "    \n",
    "    score = loss(A_3, Y)\n",
    "    \n",
    "    dZ_3 = A_3 - Y\n",
    "    dW_3 = (1./m)*np.dot(dZ_3.T, A_2)\n",
    "    db_3 = (1./m)*np.sum(dZ_3, axis=0, keepdims=True)\n",
    "    \n",
    "    dZ_2 = np.dot(dZ_3, W[3])*dA_2\n",
    "    dW_2 = (1./m)*np.dot(dZ_2.T, A_1)\n",
    "    db_2 = (1./m)*np.sum(dZ_2, axis=0, keepdims=True)\n",
    "    \n",
    "    dZ_1 = np.dot(dZ_2, W[2])*dA_1\n",
    "    dW_1 = (1./m)*np.dot(dZ_1.T, A_0)\n",
    "    db_1 = (1./m)*np.sum(dZ_1, axis=0, keepdims=True)\n",
    "    \n",
    "    W[1]-=alpha*dW_1\n",
    "    W[2]-=alpha*dW_2\n",
    "    W[3]-=alpha*dW_3\n",
    "    b[1]-=alpha*db_1\n",
    "    b[2]-=alpha*db_2\n",
    "    b[3]-=alpha*db_3\n",
    "    \n",
    "    return W, b, score\n",
    "    \n",
    "def normalize_data(data, epsilon=10e-8):\n",
    "    epsilon = 10e-8\n",
    "    mu = np.mean(data, axis=0)\n",
    "    sigma = np.var(data, axis=0)\n",
    "    norm_data = (data-mu)/(sigma+epsilon)\n",
    "    return norm_data, mu, sigma\n",
    "\n",
    "def unnormalize_data(norm_data, mu, sigma, epsilon=10e-8):\n",
    "    data = norm_data*(sigma+epsilon) + mu\n",
    "    return data\n",
    "        \n",
    "def plot_image(predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(predicted_label,\n",
    "                                100*np.max(predictions_array),\n",
    "                                true_label),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(predictions_array, true_label):\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1]) \n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = SimpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.load_data()\n",
    "nn.initialize_weights()\n",
    "#nn.load_weights(\"save/SimpleNN/\", \"500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn.train(l_rate=0.01, l_decay=0, mini_batch=64, nb_epoch=500, verbose=True, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.simple_prediction(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.save_weights('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
