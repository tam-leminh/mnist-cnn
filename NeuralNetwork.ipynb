{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def leaky_relu(x):\n",
    "    if x >=0:\n",
    "        return x\n",
    "    else:\n",
    "        return -0.01*x\n",
    "    \n",
    "def d_leaky_relu(x):\n",
    "    if x >=0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return -0.01\n",
    "    \n",
    "def softmax(x):\n",
    "    x -= np.max(x, axis=0)\n",
    "    return (np.exp(x))/(np.sum(np.exp(x), axis=0).T)\n",
    "\n",
    "def grad_clip(x):\n",
    "    #if x >=0.01:\n",
    "    #    return 0.01\n",
    "    #elif x<=-0.01:\n",
    "    #    return -0.01\n",
    "    #else:\n",
    "    #    return x\n",
    "    return x\n",
    "    \n",
    "def loss(pred, y):\n",
    "    loss = -1.*np.sum(y*np.log(pred+0.001)/y.shape[1])\n",
    "    return loss\n",
    "\n",
    "def fw_prop(X, Y, W, b):\n",
    "    m = X.shape[2]\n",
    "    n_0 = X.shape[0]*X.shape[1]\n",
    "    n_1 = W[1].shape[0]\n",
    "    n_2 = W[2].shape[0]\n",
    "    n_3 = W[3].shape[0]\n",
    "    A_0 = X.reshape((n_0,m))\n",
    "    \n",
    "    Z_1 = np.dot(W[1], A_0.reshape((n_0,m))) + b[1]\n",
    "    A_1 = np.vectorize(leaky_relu)(Z_1)\n",
    "    \n",
    "    Z_2 = np.dot(W[2], A_1.reshape((n_1,m))) + b[2]\n",
    "    A_2 = np.vectorize(leaky_relu)(Z_2)\n",
    "    \n",
    "    Z_3 = np.dot(W[3], A_2.reshape((n_2,m))) + b[3]\n",
    "    A_3 = softmax(Z_3)\n",
    "    \n",
    "    score = loss(A_3, Y)\n",
    "    return A_3, J\n",
    "\n",
    "def fw_bk_prop(X, Y, W, b, alpha):\n",
    "    m = X.shape[2]\n",
    "    n_0 = X.shape[0]*X.shape[1]\n",
    "    n_1 = W[1].shape[0]\n",
    "    n_2 = W[2].shape[0]\n",
    "    n_3 = W[3].shape[0]\n",
    "    epsilon = 10e-5\n",
    "    A_0 = X.reshape((n_0,m))\n",
    "    \n",
    "    Z_1 = np.dot(W[1], A_0.reshape((n_0,m))) + b[1]\n",
    "    A_1 = np.vectorize(leaky_relu)(Z_1)\n",
    "    dA_1 = np.vectorize(d_leaky_relu)(Z_1)\n",
    "    Z_1_papprox = np.dot(W[1], A_0.reshape((n_0,m))) + b[1]\n",
    "    A_1_papprox = np.vectorize(leaky_relu)(Z_1_papprox)\n",
    "    Z_1_mapprox = np.dot(W[1], A_0.reshape((n_0,m))) + b[1]\n",
    "    A_1_mapprox = np.vectorize(leaky_relu)(Z_1_mapprox)\n",
    "    \n",
    "    Z_2 = np.dot(W[2], A_1.reshape((n_1,m))) + b[2]\n",
    "    A_2 = np.vectorize(leaky_relu)(Z_2)\n",
    "    dA_2 = np.vectorize(d_leaky_relu)(Z_2)\n",
    "    Z_2_papprox = np.dot(W[2], A_1_papprox.reshape((n_1,m))) + b[1]\n",
    "    A_2_papprox = np.vectorize(leaky_relu)(Z_2_papprox)\n",
    "    Z_2_mapprox = np.dot(W[2], A_1_mapprox.reshape((n_1,m))) + b[1]\n",
    "    A_2_mapprox = np.vectorize(leaky_relu)(Z_2_mapprox)\n",
    "    \n",
    "    Z_3 = np.dot(W[3], A_2.reshape((n_2,m))) + b[3]\n",
    "    A_3 = softmax(Z_3)\n",
    "    Z_3_papprox = np.dot(W[3]+epsilon, A_2_papprox.reshape((n_2,m))) + b[3]\n",
    "    A_3_papprox = softmax(Z_3_papprox)\n",
    "    Z_3_mapprox = np.dot(W[3]-epsilon, A_2_mapprox.reshape((n_2,m))) + b[3]\n",
    "    A_3_mapprox = softmax(Z_3_mapprox)\n",
    "    \n",
    "    score = loss(A_3, Y)\n",
    "    papprox = loss(A_3_papprox, Y)\n",
    "    mapprox = loss(A_3_mapprox, Y)\n",
    "    d_approx = (papprox-mapprox)/(2*epsilon)\n",
    "    \n",
    "    dZ_3 = A_3 - Y\n",
    "    dW_3 = (1./m)*np.dot(dZ_3,A_2.T)\n",
    "    db_3 = (1./m)*np.sum(dZ_3, axis=1, keepdims=True)\n",
    "    \n",
    "    dZ_2 = np.dot(W[3].T,dZ_3)*dA_2\n",
    "    dW_2 = (1./m)*np.dot(dZ_2,A_1.T)\n",
    "    db_2 = (1./m)*np.sum(dZ_2, axis=1, keepdims=True)\n",
    "    \n",
    "    dZ_1 = np.dot(W[2].T,dZ_2)*dA_1\n",
    "    dW_1 = (1./m)*np.dot(dZ_1,A_0.T)\n",
    "    db_1 = (1./m)*np.sum(dZ_1, axis=1, keepdims=True)\n",
    "    \n",
    "    #print(A_3 - Y)\n",
    "    #print(\"Z_3: \" + str(np.max(np.absolute(Z_3))))\n",
    "    #print(np.linalg.norm(d_approx-dW_3))\n",
    "    #print(np.linalg.norm(d_approx))\n",
    "    #print(np.linalg.norm(dW_3))\n",
    "    #print(np.linalg.norm(d_approx-dW_3)/(np.linalg.norm(d_approx)+np.linalg.norm(dW_3)))\n",
    "    #print(\"dW_1: \" + str(np.max(np.absolute(dW_1))))\n",
    "    #print(\"dW_2: \" + str(np.max(np.absolute(dW_2))))\n",
    "    #print(\"dW_3: \" + str(np.max(np.absolute(dW_3))))\n",
    "    #print(\"db_1: \" + str(np.max(np.absolute(db_1))))\n",
    "    #print(\"db_2: \" + str(np.max(np.absolute(db_2))))\n",
    "    #print(\"db_3: \" + str(np.max(np.absolute(db_3))))\n",
    "    W[1]-=alpha*np.vectorize(grad_clip)(dW_1)\n",
    "    W[2]-=alpha*np.vectorize(grad_clip)(dW_2)\n",
    "    W[3]-=alpha*np.vectorize(grad_clip)(dW_3)\n",
    "    b[1]-=alpha*np.vectorize(grad_clip)(db_1)\n",
    "    b[2]-=alpha*np.vectorize(grad_clip)(db_2)\n",
    "    b[3]-=alpha*np.vectorize(grad_clip)(db_3)\n",
    "    \n",
    "    return W, b, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.images\n",
    "mu = np.mean(X, axis=0)\n",
    "sigma = np.var(X, axis=0)\n",
    "X = (X-mu)/(sigma+10e-8)\n",
    "labels = digits.target\n",
    "Y = np.zeros((X.shape[0], 10))\n",
    "\n",
    "for i in range(0, labels.shape[0]):\n",
    "    Y[i][labels[i]] = 1\n",
    "\n",
    "    \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=False)\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "Y_train = Y_train.T\n",
    "Y_test = Y_test.T\n",
    "n_sample_train = X_train.shape[2]\n",
    "mini_batch = 64\n",
    "number_mini_batch = n_sample_train/mini_batch + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = []\n",
    "b = []\n",
    "\n",
    "#W_1 = (1./64)*(np.random.sample((128,64)))\n",
    "#b_1 = np.zeros((128,1))\n",
    "#\n",
    "#W_2 = (1./128)*(np.random.sample((128,128)))\n",
    "#b_2 = np.zeros((128,1))\n",
    "#\n",
    "#W_3 = (1./128)*(np.random.sample((10,128)))\n",
    "#b_3 = np.zeros((10,1))\n",
    "\n",
    "W_1 = np.load('save/w1.npz')['arr_0']\n",
    "W_2 = np.load('save/w2.npz')['arr_0']\n",
    "W_3 = np.load('save/w3.npz')['arr_0']\n",
    "b_1 = np.load('save/b1.npz')['arr_0']\n",
    "b_2 = np.load('save/b2.npz')['arr_0']\n",
    "b_3 = np.load('save/b3.npz')['arr_0']\n",
    "\n",
    "W.append(0)\n",
    "W.append(W_1)\n",
    "W.append(W_2)\n",
    "W.append(W_3)\n",
    "b.append(0)\n",
    "b.append(b_1)\n",
    "b.append(b_2)\n",
    "b.append(b_3)\n",
    "\n",
    "W_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_epoch = 1000\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for e in range(0, number_epoch):\n",
    "    for i in range(0, number_mini_batch):\n",
    "        if i!=number_mini_batch-1:\n",
    "            W, b, J = fw_bk_prop(X_train[:,:,mini_batch*i:mini_batch*(i+1)], Y_train[:,mini_batch*i:mini_batch*(i+1)], W, b, alpha=0.01)\n",
    "            #print(np.max(b[1]))\n",
    "            #print(np.max(b[2]))\n",
    "            #print(np.max(b[3]))\n",
    "        else:\n",
    "            W, b, J = fw_bk_prop(X_train[:,:,mini_batch*i:], Y_train[:,mini_batch*i:], W, b, alpha=0.0001/(e+1001))\n",
    "            \n",
    "    train_losses.append(J)\n",
    "    pred, test_score = fw_prop(X_test, Y_test, W, b)\n",
    "    test_losses.append(test_score)\n",
    "    if e%10 == 0:\n",
    "        print(\"J: \" + str(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(X, axis=0)\n",
    "sigma = np.var(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_orig = X_test.T*sigma + mu\n",
    "plt.imshow((X_test.T*sigma + mu)[359])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0, 10):\n",
    "    x = X_test[:,:,j].reshape((8,8,1))\n",
    "    y = Y_test[:,j].reshape((10,1))\n",
    "    preds, score = fw_prop(x, y, W, b)\n",
    "    plt.imshow(X_test_orig[j])\n",
    "    print(np.argmax(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('e2000_w1.npz',W[1])\n",
    "np.savez_compressed('e2000_w2.npz',W[2])\n",
    "np.savez_compressed('e2000_w3.npz',W[3])\n",
    "np.savez_compressed('e2000_b1.npz',b[1])\n",
    "np.savez_compressed('e2000_b2.npz',b[2])\n",
    "np.savez_compressed('e2000_b3.npz',b[3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
